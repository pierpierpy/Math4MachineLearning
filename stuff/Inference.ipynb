{"cells":[{"cell_type":"code","execution_count":null,"id":"7b51d06d","metadata":{"id":"7b51d06d"},"outputs":[],"source":["import torch\n","from torch.utils.data import TensorDataset, DataLoader\n","import pandas as pd\n","from torch import nn\n","import torch.nn.functional as F"]},{"cell_type":"code","execution_count":null,"id":"e9e6e303","metadata":{"id":"e9e6e303"},"outputs":[],"source":["class Net(nn.Module):\n","    def __init__(self):\n","        nn.Module.__init__(self)\n","        self.fc1 = nn.Linear(784, 28**2*4)\n","        self.fc2 = nn.Linear(28**2*4, 28**2*4)\n","        self.fc3 = nn.Linear(28**2*4, 10)\n","\n","    def forward(self, x):\n","        # x: [N, 1, 28, 28] -> [N, 784]\n","        # N elements in each batch, 1 is the number of channels per pixel, in our case the image is grey scaled, so it is 1\n","        # 28 and 28 represent the grid --> 28*29 = 784\n","        # x = x.view(x.size(0), -1)\n","        # it is better to directly import the dataset with the right format, infact is what i did\n","\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        logits = self.fc3(x)\n","        return logits"]},{"cell_type":"code","execution_count":null,"id":"09e3da91","metadata":{"id":"09e3da91","outputId":"b228e08e-bafc-431a-8a44-5a735fde53ef"},"outputs":[{"data":{"text/plain":["Net(\n","  (fc1): Linear(in_features=784, out_features=3136, bias=True)\n","  (fc2): Linear(in_features=3136, out_features=3136, bias=True)\n","  (fc3): Linear(in_features=3136, out_features=10, bias=True)\n",")"]},"execution_count":73,"metadata":{},"output_type":"execute_result"}],"source":["model = Net()\n","state_dict = torch.load(\"models/model.pth\")\n","model.load_state_dict(state_dict)\n","\n","model.eval()"]},{"cell_type":"code","execution_count":null,"id":"8ffef313","metadata":{"id":"8ffef313"},"outputs":[],"source":["data = pd.read_csv(\"data/mnist_train_small.csv\", header = None)"]},{"cell_type":"code","execution_count":null,"id":"d769a534","metadata":{"id":"d769a534"},"outputs":[],"source":["X_test = torch.tensor(data.iloc[:, 1:].values, dtype = torch.float32)\n","Y_test = torch.tensor(data.iloc[:, 0].values,dtype = torch.float32)"]},{"cell_type":"code","execution_count":null,"id":"cca688fc","metadata":{"id":"cca688fc"},"outputs":[],"source":["dataset = TensorDataset(X_test, Y_test)"]},{"cell_type":"code","execution_count":null,"id":"03a36d61","metadata":{"id":"03a36d61"},"outputs":[],"source":["loader = DataLoader(dataset, batch_size=64)"]},{"cell_type":"code","execution_count":null,"id":"413b70c9","metadata":{"id":"413b70c9"},"outputs":[],"source":["input, target = next(iter(loader))"]},{"cell_type":"code","execution_count":null,"id":"3c9f7161","metadata":{"id":"3c9f7161","outputId":"6bc0a800-451c-45b9-e838-ac3225a87bc0"},"outputs":[{"data":{"text/plain":["tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.],\n","        [0., 0., 0.,  ..., 0., 0., 0.]])"]},"execution_count":85,"metadata":{},"output_type":"execute_result"}],"source":["input"]},{"cell_type":"code","execution_count":null,"id":"d3eb848a","metadata":{"id":"d3eb848a"},"outputs":[],"source":["with torch.no_grad():\n","    output = model(input).argmax(dim=-1)\n"]},{"cell_type":"code","execution_count":null,"id":"b5082d5a","metadata":{"id":"b5082d5a","outputId":"d35bef91-28d2-4b07-dc42-1f2341f3c353"},"outputs":[{"data":{"text/plain":["tensor([6, 5, 7, 9, 5, 2, 0, 6, 5, 5, 2, 7, 7, 6, 8, 9, 3, 5, 7, 6, 9, 4, 3, 4,\n","        9, 2, 9, 1, 3, 9, 7, 7, 5, 8, 6, 1, 7, 2, 7, 8, 8, 7, 1, 3, 7, 4, 1, 1,\n","        9, 2, 9, 2, 0, 9, 7, 8, 2, 0, 2, 6, 3, 5, 6, 2])"]},"execution_count":96,"metadata":{},"output_type":"execute_result"}],"source":["output"]}],"metadata":{"kernelspec":{"display_name":"main","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.11"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}